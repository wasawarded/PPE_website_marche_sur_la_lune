          + 3.4 Evolutionary learning
     * 4 List of implementations
     * 5 Probabilistic inductive logic programming
       (BUTTON) Toggle Probabilistic inductive logic programming
       subsection
          + 5.1 Parameter Learning
--
   [ ] Toggle the table of contents

Inductive logic programming

   [ ] 13 languages
--
   (BUTTON) move to sidebar (BUTTON) hide
   From Wikipedia, the free encyclopedia
   [220px-ILP_family2.png] A photo of Family sample for Inductive Logic
   Programming article

   Inductive logic programming (ILP) is a subfield of symbolic artificial
   intelligence which uses logic programming as a uniform representation
   for examples, background knowledge and hypotheses. The term "inductive"
   here refers to philosophical (i.e. suggesting a theory to explain
--
   known background knowledge and a set of examples represented as a
   logical database of facts, an ILP system will derive a hypothesised
   logic program which entails all the positive and none of the negative
   examples.
     * Schema: positive examples + negative examples + background
       knowledge ⇒ hypothesis.

   Inductive logic programming is particularly useful in bioinformatics
   and natural language processing.

--
   examples.^[1]^[3] His first implementation was the Model Inference
   System in 1981:^[4]^[5] a Prolog program that inductively inferred Horn
   clause logic programs from positive and negative examples.^[1] The term
   Inductive Logic Programming was first introduced in a paper by Stephen
   Muggleton in 1990, defined as the intersection of machine learning and
   logic programming.^[1] Muggleton and Wray Buntine introduced predicate
   invention and inverse resolution in 1988.^[1]^[6]

   Several inductive logic programming systems that proved influential
   appeared in the early 1990s. FOIL, introduced by Ross Quinlan in
   1990^[7] was based on upgrading propositional learning algorithms AQ
--

   At around the same time, the first practical applications emerged,
   particularly in bioinformatics, where by 2000 inductive logic
   programming had been successfully applied to drug design,
   carcinogenicity and mutagenicity prediction, and elucidation of the
   structure and function of proteins.^[12] Unlike the focus on automatic
   programming inherent in the early work, these fields used inductive
   logic programming techniques from a viewpoint of relational data
   mining. The success of those initial applications and the lack of
   progress in recovering larger traditional logic programs shaped the
   focus of the field.^[13]

--
   [edit]

   Inductive logic programming has adopted several different learning
   settings, the most common of which are learning from entailment and
   learning from interpretations.^[16] In both cases, the input is
   provided in the form of background knowledge B, a logical theory
   (commonly in the form of clauses used in logic programming), as well as
   positive and negative examples, denoted
   [MATH: <semantics> <mrow class="MJX-TeXAtom-ORD"> <mstyle
--

   As of 2022^[update], learning from entailment is by far the most
   popular setting for inductive logic programming.^[16] In this setting,
   the positive and negative examples are given as finite sets
   [MATH: <semantics> <mrow class="MJX-TeXAtom-ORD"> <mstyle
--
   [edit]

   An inductive logic programming system is a program that takes as an
   input logic theories
   [MATH: <semantics> <mrow class="MJX-TeXAtom-ORD"> <mstyle
   displaystyle="true" scriptlevel="0"> <mi>B</mi> <mo>,</mo> <msup>
--
   </semantics> :MATH]
   {\displaystyle B,E^{+},E^{-}} . A system is complete if and only if for
   any input logic theories
   [MATH: <semantics> <mrow class="MJX-TeXAtom-ORD"> <mstyle
   displaystyle="true" scriptlevel="0"> <mi>B</mi> <mo>,</mo> <msup>
--
   {\displaystyle B,E^{+},E^{-}} any correct hypothesis H with respect to
   these input theories can be found with its hypothesis search procedure.
   Inductive logic programming systems can be roughly divided into two
   classes, search-based and meta-interpretative systems.

--
   Bottom-up methods to search the subsumption lattice have been
   investigated since Plotkin's first work on formalising induction in
   clausal logic in 1970.^[1]^[20] Techniques used include least general
   generalisation, based on anti-unification, and inverse resolution,
   based on inverting the resolution inference rule.
--
   first-order syntactical anti-unification.^[21]

   To account for background knowledge, inductive logic programming
   systems employ relative least general generalisations, which are
   defined in terms of subsumption relative to a background theory. In
--
   Inverse resolution takes information about the resolvent of a
   resolution step to compute possible resolving clauses. Two types of
   inverse resolution operator are in use in inductive logic programming:
   V-operators and W-operators. A V-operator takes clauses
   [MATH: <semantics> <mrow class="MJX-TeXAtom-ORD"> <mstyle
--

   Inverse resolution was first introduced by Stephen Muggleton and Wray
   Buntine in 1988 for use in the inductive logic programming system
   Cigol.^[6] By 1993, this spawned a surge of research into inverse
   resolution operators and their properties.^[23]
--

   Questions of completeness of a hypothesis search procedure of specific
   inductive logic programming system arise. For example, the Progol
   hypothesis search procedure based on the inverse entailment inference
   rule is not complete by Yamamoto's example.^[27] On the other hand,
--

   Rather than explicitly searching the hypothesis graph, metainterpretive
   or meta-level systems encode the inductive logic programming program as
   a meta-level logic program which is then solved to obtain an optimal
   hypothesis. Formalisms used to express the problem specification
   include Prolog and answer set programming, with existing Prolog systems
--
   And example of a Prolog-based system is Metagol, which is based on a
   meta-interpreter in Prolog, while ASPAL and ILASP are based on an
   encoding of the inductive logic programming problem in answer set
   programming.^[30]

--
     * ProGolem ^[32]^[33]

Probabilistic inductive logic programming

   [edit]

   Probabilistic inductive logic programming adapts the setting of
   inductive logic programming to learning probabilistic logic programs.
   It can be considered as a form of statistical relational learning
   within the formalism of probabilistic logic programming.^[34]^[35]

   Given
    1. background knowledge as a probabilistic logic program B, and
    2. a set of positive and negative examples
       [MATH: <semantics> <mrow class="MJX-TeXAtom-ORD"> <mstyle
--
       {\textstyle E^{-}}

   the goal of probabilistic inductive logic programming is to find a
   probabilistic logic program
   [MATH: <semantics> <mrow class="MJX-TeXAtom-ORD"> <mstyle
   displaystyle="false" scriptlevel="0"> <mi>H</mi> </mstyle> </mrow>
--
   clauses, while in the latter the goal is to infer both the structure
   and the probability parameters of H. Just as in classical inductive
   logic programming, the examples can be given as examples or as
   (partial) interpretations.^[35]

--

   In the same year, Meert, W. et al. introduced a method for learning
   parameters and structure of ground probabilistic logic programs by
   considering the Bayesian networks equivalent to them and applying
   techniques for learning Bayesian networks.^[38]^[35]

   ProbFOIL, introduced by De Raedt and Ingo Thon in 2010, combined the
   inductive logic programming system FOIL with ProbLog. Logical rules are
   learned from probabilistic data in the sense that both the examples
   themselves and their classifications can be probabilistic. The set of
--

   In 2011, Elena Bellodi and Fabrizio Riguzzi introduced SLIPCASE, which
   performs a beam search among probabilistic logic programs by
   iteratively refining probabilistic theories and optimizing the
   parameters of each theory using expectation-maximisation.^[40] Its
--
   [edit]
    1. ^ ^a ^b ^c ^d ^e ^f Nienhuys-Cheng, Shan-hwei; Wolf, Ronald de
       (1997). Foundations of inductive logic programming. Lecture notes
       in computer science Lecture notes in artificial intelligence.
       Berlin Heidelberg: Springer. pp. 174–177. ISBN 978-3-540-62927-6.
--
       Yale University. 192. Reprinted in

   Lassez, J.-L.; Plotkin, G., eds. (1991). Computational logic : essays
   in honor of Alan Robinson. MIT Press. pp. 199–254.
   ISBN 978-0-262-12156-9.
--

     ^ ^a ^b ^c ^d Nienhuys-Cheng, Shan-hwei; Wolf, Ronald de (1997).
   Foundations of inductive logic programming. Lecture notes in computer
   science Lecture notes in artificial intelligence. Berlin Heidelberg:
   Springer. pp. 354–358. ISBN 978-3-540-62927-6.
--
     ^ ^a ^b Muggleton, Stephen H.; Feng, Cao (1990). Arikawa, Setsuo;
   Goto, Shigeki; Ohsuga, Setsuo; Yokomori, Takashi (eds.). "Efficient
   Induction of Logic Programs". Algorithmic Learning Theory, First
   International Workshop, ALT '90, Tokyo, Japan, October 8–10, 1990,
   Proceedings. Springer/Ohmsha: 368–381.

     ^ ^a ^b Cropper, Andrew; Dumančić, Sebastijan (2022-06-15).
   "Inductive Logic Programming At 30: A New Introduction". Journal of
   Artificial Intelligence Research. 74: 808. arXiv:2008.07912.
   doi:10.1613/jair.1.13507. ISSN 1076-9757.
--

     ^ Cropper, Andrew; Dumančić, Sebastijan; Evans, Richard; Muggleton,
   Stephen (2022). "Inductive logic programming at 30". Machine Learning.
   111 (1): 147–172. doi:10.1007/s10994-021-06089-1. ISSN 0885-6125.

     ^ ^a ^b ^c ^d Cropper, Andrew; Dumančić, Sebastijan (2022-06-15).
   "Inductive Logic Programming At 30: A New Introduction". Journal of
   Artificial Intelligence Research. 74: 779–782. arXiv:2008.07912.
   doi:10.1613/jair.1.13507. ISSN 1076-9757.

     ^ Džeroski, Sašo (1996). "Inductive Logic Programming and Knowledge
   Discovery in Databases" (PDF). In Fayyad, U.M.; Piatetsky-Shapiro, G.;
   Smith, P.; Uthurusamy, R. (eds.). Advances in Knowledge Discovery and
--
   doi:10.1016/S0004-3702(97)00041-6.

     ^ ^a ^b Muggleton, Stephen (1999). "Inductive Logic Programming:
   Issues, Results and the Challenge of Learning Language in Logic".
   Artificial Intelligence. 114 (1–2): 283–296.
   doi:10.1016/s0004-3702(99)00067-3.; here: Sect.2.1
--

     ^ Nienhuys-Cheng, Shan-hwei; Wolf, Ronald de (1997). Foundations of
   inductive logic programming. Lecture notes in computer science Lecture
   notes in artificial intelligence. Berlin Heidelberg: Springer. p. 255.
   ISBN 978-3-540-62927-6.

     ^ Nienhuys-Cheng, Shan-hwei; Wolf, Ronald de (1997). Foundations of
   inductive logic programming. Lecture notes in computer science Lecture
   notes in artificial intelligence. Berlin Heidelberg: Springer. p. 286.
   ISBN 978-3-540-62927-6.

     ^ ^a ^b Nienhuys-Cheng, Shan-hwei; Wolf, Ronald de (1997).
   Foundations of inductive logic programming. Lecture notes in computer
   science Lecture notes in artificial intelligence. Berlin Heidelberg:
   Springer. p. 197. ISBN 978-3-540-62927-6.
--
     ^ Ray, O.; Broda, K.; Russo, A.M. (2003). "Hybrid abductive inductive
   learning". Proceedings of the 13th international conference on
   inductive logic programming. LNCS. Vol. 2835. Springer. pp. 311–328.
   CiteSeerX 10.1.1.212.6602. doi:10.1007/978-3-540-39917-9_21.
   ISBN 978-3-540-39917-9.
--
     ^ Kimber, T.; Broda, K.; Russo, A. (2009). "Induction on failure:
   learning connected Horn theories". Proceedings of the 10th
   international conference on logic programing and nonmonotonic
   reasoning. LNCS. Vol. 575. Springer. pp. 169–181.
   doi:10.1007/978-3-642-04238-6_16. ISBN 978-3-642-04238-6.
--

     ^ Yamamoto, Akihiro (1997). "Which hypotheses can be found with
   inverse entailment?". International Conference on Inductive Logic
   Programming. Lecture Notes in Computer Science. Vol. 1297. Springer.
   pp. 296–308. CiteSeerX 10.1.1.54.2975. doi:10.1007/3540635149_58.
   ISBN 978-3-540-69587-5.

     ^ ^a ^b Kimber, Timothy (2012). Learning definite and normal logic
   programs by induction on failure (PhD). Imperial College London. ethos
   560694. Archived from the original on 2022-10-21. Retrieved 2022-10-21.
--

     ^ ^a ^b Cropper, Andrew; Dumančić, Sebastijan (2022-06-15).
   "Inductive Logic Programming At 30: A New Introduction". Journal of
   Artificial Intelligence Research. 74: 795. arXiv:2008.07912.
   doi:10.1613/jair.1.13507. ISSN 1076-9757.
--
     ^ Muggleton, Stephen; Santos, Jose; Tamaddoni-Nezhad, Alireza (2009).
   "ProGolem: a system based on relative minimal generalization".
   International Conference on Inductive Logic Programming. Springer.
   pp. 131–148. CiteSeerX 10.1.1.297.7992.
   doi:10.1007/978-3-642-13840-9_13. ISBN 978-3-642-13840-9.
--
     ^ Santos, Jose; Nassif, Houssam; Page, David; Muggleton, Stephen;
   Sternberg, Mike (2012). "Automated identification of features of
   protein-ligand interactions using Inductive Logic Programming: a hexose
   binding case study". BMC Bioinformatics. 13: 162.
   doi:10.1186/1471-2105-13-162. PMC 3458898. PMID 22783946.

     ^ De Raedt, Luc; Kersting, Kristian (2008), Probabilistic Inductive
   Logic Programming, Berlin, Heidelberg: Springer Berlin Heidelberg,
   pp. 1–27, doi:10.1007/978-3-540-78652-8_1, ISBN 978-3-540-78651-1,
   retrieved 2023-12-09

     ^ ^a ^b ^c ^d ^e ^f ^g ^h ^i Riguzzi, Fabrizio; Bellodi, Elena; Zese,
   Riccardo (2014-09-18). "A History of Probabilistic Inductive Logic
   Programming". Frontiers in Robotics and AI. 1.
   doi:10.3389/frobt.2014.00006. ISSN 2296-9144.
--
     ^ Blockeel, Hendrik; Meert, Wannes (2007), "Towards Learning
   Non-recursive LPADs by Transforming Them into Bayesian Networks",
   Inductive Logic Programming, Lecture Notes in Computer Science,
   vol. 4455, Berlin, Heidelberg: Springer Berlin Heidelberg, pp. 94–108,
   doi:10.1007/978-3-540-73847-3_16, ISBN 978-3-540-73846-6, retrieved
--

     ^ De Raedt, Luc; Thon, Ingo (2011), Frasconi, Paolo; Lisi, Francesca
   A. (eds.), "Probabilistic Rule Learning", Inductive Logic Programming,
   vol. 6489, Berlin, Heidelberg: Springer Berlin Heidelberg, pp. 47–58,
   doi:10.1007/978-3-642-21295-6_9, ISBN 978-3-642-21294-9,
--

     ^ Bellodi, Elena; Riguzzi, Fabrizio (2012), "Learning the Structure
   of Probabilistic Logic Programs", Inductive Logic Programming, Berlin,
   Heidelberg: Springer Berlin Heidelberg, pp. 61–75,
   doi:10.1007/978-3-642-31951-8_10, ISBN 978-3-642-31950-1, retrieved
--

     ^ Bellodi, Elena; Riguzzi, Fabrizio (2014-01-15). "Structure learning
   of probabilistic logic programs by searching the clause space". Theory
   and Practice of Logic Programming. 15 (2): 169–212. arXiv:1309.2080.
   doi:10.1017/s1471068413000689. ISSN 1471-0684. S2CID 17669522.

--
   article incorporates text from a free content work. Licensed under
   CC-BY 4.0 (license statement/permission). Text taken from A History of
   Probabilistic Inductive Logic Programming​, Fabrizio Riguzzi, Elena
   Bellodi and Riccardo Zese, Frontiers Media.

--
     *

   Muggleton, S.; De Raedt, L. (1994). "Inductive Logic Programming:
   Theory and methods". The Journal of Logic Programming. 19–20: 629–679.
   doi:10.1016/0743-1066(94)90035-3.

     Lavrac, N.; Dzeroski, S. (1994). Inductive Logic Programming:
   Techniques and Applications. New York: Ellis Horwood.
   ISBN 978-0-13-457870-5. Archived from the original on 2004-09-06.
--
     * GADTs
     * Dependent types
     * Functional logic
     * Point-free style
     * Expression-oriented
--
     * Synchronous

   Logic
     * Abductive logic
     * Answer set
     * Constraint (Constraint logic)
     * Inductive logic
     * Nondeterministic
     * Ontology
     * Probabilistic logic
     * Query

--
     * Automatic mutual exclusion
     * Choreographic programming
     * Concurrent logic (Concurrent constraint logic)
     * Concurrent OO
     * Macroprogramming
--

   Category:
     * Inductive logic programming

   Hidden categories:
